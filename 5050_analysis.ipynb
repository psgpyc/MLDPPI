{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d402bb45-a67f-4e5e-b092-e593fdf7ea7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b13e8e1-99be-403a-ba2c-69af1b5020e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "378fc1c7-e1e2-4bc9-b104-7f2d03854164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model preprocessing\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder \n",
    "\n",
    "# model training\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn import datasets, linear_model, metrics\n",
    "\n",
    "# model evaluation\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, ConfusionMatrixDisplay, precision_score, recall_score, f1_score, classification_report, roc_curve, auc, precision_recall_curve, average_precision_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from collections import Counter\n",
    "\n",
    "# to save the model\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9460b5a-2600-4815-af89-a77e7f6a87e6",
   "metadata": {},
   "source": [
    "## Pre-processing to gain 50-50 sample for each of the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e20a033b-f14d-44dd-abff-458121652717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the dataset\n",
    "df = pd.read_csv(\"./dataset/dropped_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f2074c4-da4c-4f60-b2b5-a18f7eb826f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['has_diabetes'] = df['has_diabetes'].astype('bool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c0ba026-1a50-4ae7-ae40-6651d8ba6f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only selecting rows without diabates\n",
    "df_has_diabetes_class_0 = df[df['has_diabetes'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43a5fcc1-ba0c-4182-ab60-3f51bef6ab6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only selecting rows with diabates\n",
    "df_has_diabetes_class_1 = df[df['has_diabetes'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1fadbb2-4f5d-4285-90a9-c4d286c6b45b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_diabetes</th>\n",
       "      <th>BMI</th>\n",
       "      <th>age</th>\n",
       "      <th>total_household_income</th>\n",
       "      <th>smoking</th>\n",
       "      <th>high_bp</th>\n",
       "      <th>high_chol</th>\n",
       "      <th>heart_diseases</th>\n",
       "      <th>asthma</th>\n",
       "      <th>kidney_diseases</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>education</th>\n",
       "      <th>general_health</th>\n",
       "      <th>physical_activity</th>\n",
       "      <th>arthritis</th>\n",
       "      <th>depression</th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   has_diabetes  BMI  age  total_household_income  smoking  high_bp  \\\n",
       "0         False  3.0  6.0                     9.0      4.0      2.0   \n",
       "1         False  2.0  6.0                     1.0      3.0      2.0   \n",
       "2         False  3.0  6.0                     9.0      4.0      1.0   \n",
       "3         False  4.0  5.0                     5.0      4.0      2.0   \n",
       "4         False  2.0  6.0                     4.0      3.0      1.0   \n",
       "\n",
       "   high_chol  heart_diseases  asthma  kidney_diseases  marital_status  \\\n",
       "0        2.0             2.0     3.0              2.0             2.0   \n",
       "1        2.0             2.0     1.0              2.0             3.0   \n",
       "2        1.0             2.0     3.0              2.0             1.0   \n",
       "3        2.0             2.0     3.0              2.0             3.0   \n",
       "4        1.0             2.0     3.0              2.0             3.0   \n",
       "\n",
       "   education  general_health  physical_activity  arthritis  depression  sex  \\\n",
       "0        3.0             1.0                1.0        1.0         1.0  2.0   \n",
       "1        2.0             2.0                9.0        1.0         2.0  2.0   \n",
       "2        3.0             1.0                9.0        1.0         1.0  2.0   \n",
       "3        3.0             1.0                9.0        2.0         2.0  2.0   \n",
       "4        2.0             2.0                4.0        1.0         2.0  1.0   \n",
       "\n",
       "   race  \n",
       "0   1.0  \n",
       "1   2.0  \n",
       "2   1.0  \n",
       "3   2.0  \n",
       "4   1.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_has_diabetes_class_0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c0f794-f0b5-4983-b0c7-5679d8d704a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e08f11c-e7a7-4836-85fc-20a981322e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a random permutation of indices\n",
    "random_indices = np.random.permutation(df_has_diabetes_class_0.index)\n",
    "\n",
    "# Select the first 17,417 rows based on the shuffled indices\n",
    "sampled_df = df.iloc[random_indices[:17417]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c2abd24-d49f-4c09-b3fe-0accfb490a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining splitted datasets with class 0 and 1\n",
    "df = pd.concat([df_has_diabetes_class_1, sampled_df], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02124d30-82b5-450f-91d6-d461c98cf001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "has_diabetes\n",
       "True     17417\n",
       "False    17417\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['has_diabetes'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dde70b6d-249c-4098-83ed-a60fd8e83f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('./dataset/sampled_50_50_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c33f710-89c0-476a-afc4-fb3b20bde012",
   "metadata": {},
   "source": [
    "## Chi Square test for categorical columns\n",
    "\n",
    "We are looking into the correlation between our categorical features(all of them) and target class label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71e30c2b-c2fd-4206-b05d-913f942eb2b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'has_diabetes': 0.0,\n",
       " 'BMI': 0.0,\n",
       " 'age': 0.0,\n",
       " 'total_household_income': 3.311844346816984e-302,\n",
       " 'smoking': 1.823383841895033e-52,\n",
       " 'high_bp': 0.0,\n",
       " 'high_chol': 0.0,\n",
       " 'heart_diseases': 1.0901730206498645e-296,\n",
       " 'asthma': 2.5458224846247645e-32,\n",
       " 'kidney_diseases': 4.276376242074078e-274,\n",
       " 'marital_status': 8.380689822285263e-132,\n",
       " 'education': 7.075384483712028e-145,\n",
       " 'general_health': 0.0,\n",
       " 'physical_activity': 0.0,\n",
       " 'arthritis': 0.0,\n",
       " 'depression': 1.8575181820199742e-33,\n",
       " 'sex': 5.840051060264736e-09,\n",
       " 'race': 4.028545725978419e-51}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_cols = ['has_diabetes', 'BMI', 'age', 'total_household_income', 'smoking',\n",
    "       'high_bp', 'high_chol', 'heart_diseases', 'asthma', 'kidney_diseases',\n",
    "       'marital_status', 'education', 'general_health', 'physical_activity',\n",
    "       'arthritis', 'depression', 'sex', 'race']\n",
    "\n",
    "# empty dict to store the p-value\n",
    "chi_square_test_results = {}\n",
    "\n",
    "for each_cols in categorical_cols:\n",
    "    # Create a contingency table between the features and target label\n",
    "    contingency_table = pd.crosstab(df[each_cols], df['has_diabetes'])\n",
    "    \n",
    "    # Perform the Chi-square test\n",
    "    chi2, p, _, _ = chi2_contingency(contingency_table)\n",
    "\n",
    "    # store the p-value \n",
    "    chi_square_test_results[each_cols] = p\n",
    "\n",
    "chi_square_test_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d3a8c9-94e6-4cd9-a4e0-518ce2d1a7d0",
   "metadata": {},
   "source": [
    "The p-values from the Chi-square tests suggest that there is a strong statistical association between the categorical variables and the target variable (has_diabetes), as most of the p-values are extremely small (below 0.05), indicating a significant relationship. Here’s a breakdown of the results:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e1d487-02b9-49eb-ac70-0142110d6de2",
   "metadata": {},
   "source": [
    "### Encoding the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab38b00f-8244-436a-bf93-39f685b27544",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cate_encoder(df, cols, encoder):\n",
    "    for each in cols:\n",
    "        df[each] = encoder.fit_transform(df[each])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8708e161-7a7b-494f-85ae-7b7e9cb8b187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_diabetes</th>\n",
       "      <th>BMI</th>\n",
       "      <th>age</th>\n",
       "      <th>total_household_income</th>\n",
       "      <th>smoking</th>\n",
       "      <th>high_bp</th>\n",
       "      <th>high_chol</th>\n",
       "      <th>heart_diseases</th>\n",
       "      <th>asthma</th>\n",
       "      <th>kidney_diseases</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>education</th>\n",
       "      <th>general_health</th>\n",
       "      <th>physical_activity</th>\n",
       "      <th>arthritis</th>\n",
       "      <th>depression</th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34829</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34830</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34831</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34832</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34833</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34834 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       has_diabetes  BMI  age  total_household_income  smoking  high_bp  \\\n",
       "0                 1    3    5                       4        2        1   \n",
       "1                 1    1    5                       4        3        0   \n",
       "2                 1    2    4                       5        0        1   \n",
       "3                 1    3    5                       4        3        0   \n",
       "4                 1    2    5                       7        3        1   \n",
       "...             ...  ...  ...                     ...      ...      ...   \n",
       "34829             0    1    5                       3        3        1   \n",
       "34830             0    2    4                       7        3        1   \n",
       "34831             0    1    5                       0        3        1   \n",
       "34832             0    2    3                       5        3        1   \n",
       "34833             0    3    4                       4        3        1   \n",
       "\n",
       "       high_chol  heart_diseases  asthma  kidney_diseases  marital_status  \\\n",
       "0              0               1       2                1               2   \n",
       "1              0               1       2                1               0   \n",
       "2              1               1       2                1               0   \n",
       "3              1               1       2                1               6   \n",
       "4              1               1       2                1               2   \n",
       "...          ...             ...     ...              ...             ...   \n",
       "34829          1               0       2                1               2   \n",
       "34830          0               1       2                1               0   \n",
       "34831          0               1       2                1               1   \n",
       "34832          1               1       2                1               0   \n",
       "34833          1               1       2                1               1   \n",
       "\n",
       "       education  general_health  physical_activity  arthritis  depression  \\\n",
       "0              3               0                  3          0           0   \n",
       "1              3               0                  0          1           1   \n",
       "2              1               0                  3          1           0   \n",
       "3              2               0                  3          0           1   \n",
       "4              1               0                  3          0           1   \n",
       "...          ...             ...                ...        ...         ...   \n",
       "34829          1               0                  0          1           1   \n",
       "34830          3               0                  0          1           1   \n",
       "34831          1               1                  0          1           1   \n",
       "34832          2               0                  1          1           1   \n",
       "34833          2               0                  4          1           1   \n",
       "\n",
       "       sex  race  \n",
       "0        1     0  \n",
       "1        0     0  \n",
       "2        1     0  \n",
       "3        1     0  \n",
       "4        1     0  \n",
       "...    ...   ...  \n",
       "34829    1     0  \n",
       "34830    0     0  \n",
       "34831    0     7  \n",
       "34832    0     0  \n",
       "34833    0     0  \n",
       "\n",
       "[34834 rows x 18 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encoding categorical variables \n",
    "encoder = LabelEncoder()\n",
    "df = cate_encoder(df=df, cols=df.columns, encoder=encoder)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499b0c4f-0c2c-4467-bd9d-8551d54e23e2",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a072525a-cbba-4549-9a03-f315bc47f0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['BMI', 'age', 'total_household_income', 'smoking',\n",
    "       'high_bp', 'high_chol', 'heart_diseases', 'asthma', 'kidney_diseases',\n",
    "       'marital_status', 'education', 'general_health', 'physical_activity',\n",
    "       'arthritis', 'depression', 'sex', 'race']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2964ed6e-2496-4d70-a824-3d1829e3a380",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['has_diabetes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8f29d7e-c949-42f6-b0fa-657a5e4bd6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8205d8-3c8e-44e3-b00b-630247ec2081",
   "metadata": {},
   "source": [
    "## Standardising the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fdfcbd9c-308e-4165-9a25-3d70f74d209b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating StandardScaler instance\n",
    "standard_scaler = StandardScaler()\n",
    "\n",
    "# Fitting Standard Scaller\n",
    "X_train = standard_scaler.fit_transform(X_train)\n",
    "\n",
    "# Scaling data\n",
    "X_test = standard_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65506f51-8355-46a9-9e58-01f2f399c65b",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86cfcaa8-3ee0-4b21-b0f2-f5521ca7b512",
   "metadata": {},
   "source": [
    "## Logistic Regression and Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "296d4371-3508-48cb-88ed-4f435b4eea6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accurancy_score(y, predicted_y):\n",
    "    \"\"\"\n",
    "    A function that will generate accurancy and classification report of a model\n",
    "    \n",
    "    \"\"\"\n",
    "    accurancy = accuracy_score(y, predicted_y)\n",
    "    class_report = classification_report(y, predicted_y)\n",
    "\n",
    "    return accurancy, class_report\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e0eb2fde-fa73-4509-b7e3-21d13aab10c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_and_train(model_parameters, model_class, X, y, random_state=42):\n",
    "    \"\"\"\n",
    "    A function to generate best hyperparameter for the model using GridSearchCV.\n",
    "\n",
    "    Returns: \n",
    "    best paramaters(dict) and best estimator(model)\n",
    "    \"\"\"\n",
    "    \n",
    "    model = model_class(random_state=random_state)\n",
    "    \n",
    "    model_gridsearch = GridSearchCV(model, model_parameters, cv=5, scoring='accuracy')\n",
    "    \n",
    "    model_gridsearch.fit(X, y)\n",
    "\n",
    "    return model_gridsearch.best_params_, model_gridsearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "99880e00-d49b-497d-b608-2ec709718a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "622e4a1d-4e0c-41f3-bb25-019361a460b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for Logistic Regression: {'C': 0.01, 'solver': 'lbfgs'}\n",
      "Logistic Regression Accuracy: 0.739163716390776\n",
      "Logistic Regression Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.72      0.73      5246\n",
      "           1       0.73      0.76      0.74      5205\n",
      "\n",
      "    accuracy                           0.74     10451\n",
      "   macro avg       0.74      0.74      0.74     10451\n",
      "weighted avg       0.74      0.74      0.74     10451\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_reg_params = {\n",
    "    'C': [0.01, 0.1, 1, 10],\n",
    "    'solver': ['liblinear', 'newton-cg', 'lbfgs']\n",
    "}\n",
    "\n",
    "\n",
    "log_reg_best_params, log_res_model = tune_and_train(model_parameters=log_reg_params,\n",
    "                                                    model_class=LogisticRegression, \n",
    "                                                    X=X_train, \n",
    "                                                    y=y_train)\n",
    "\n",
    "# Best parameters for Logistic Regression\n",
    "print(\"Best Parameters for Logistic Regression:\", log_reg_best_params)\n",
    "\n",
    "# Predictions\n",
    "log_reg_pred = log_res_model.predict(X_test)\n",
    "\n",
    "log_res_acc, log_res_class_report = get_accurancy_score(y_test, log_reg_pred)\n",
    "\n",
    "# Accuracy and Classification Report\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, log_reg_pred))\n",
    "print(\"Logistic Regression Classification Report:\\n\", classification_report(y_test, log_reg_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba31fd50-859e-45a1-beef-d0b0916b2f2f",
   "metadata": {},
   "source": [
    "### Dumping Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bf03f5bf-3a60-48f0-a227-aa9d3f854237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./models/logistic_reg_model.pkl']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(log_res_model, './models/logistic_reg_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29e5580-4c0e-4b76-bd0a-3814e32414c1",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "059d25ee-de9c-4ed1-93f3-8142b22eb889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for Random Forest Classifier: {'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Random Forrest Classifier Accuracy: 0.7420342550952062\n",
      "Random Forrest Classifier Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.69      0.73      5246\n",
      "           1       0.72      0.80      0.76      5205\n",
      "\n",
      "    accuracy                           0.74     10451\n",
      "   macro avg       0.75      0.74      0.74     10451\n",
      "weighted avg       0.75      0.74      0.74     10451\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_params = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "rf_best_params, rf_model = tune_and_train(model_parameters=rf_params,\n",
    "                                                    model_class=RandomForestClassifier, \n",
    "                                                    X=X_train, \n",
    "                                                    y=y_train)\n",
    "\n",
    "# Best parameters for Logistic Regression\n",
    "print(\"Best Parameters for Random Forest Classifier:\", rf_best_params)\n",
    "\n",
    "# Predictions\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "\n",
    "rf_acc, rf_class_report = get_accurancy_score(y_test, rf_pred)\n",
    "\n",
    "# Accuracy and Classification Report\n",
    "print(\"Random Forrest Classifier Accuracy:\", accuracy_score(y_test, rf_pred))\n",
    "print(\"Random Forrest Classifier Classification Report:\\n\", classification_report(y_test, rf_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9f6f1a-cfe6-4f50-b232-c18d13e6a7d3",
   "metadata": {},
   "source": [
    "#### Dumping Random Forest Models\n",
    "\n",
    "joblib.dump(rf_model, './models/random_forest_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12563a00-5281-46d6-b565-88a74b9d6ca2",
   "metadata": {},
   "source": [
    "# Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c34f5c7a-ded8-4dc3-96a1-4bab8a8319f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for SVM: {'C': 1, 'coef0': 1, 'degree': 2, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "SVM Accuracy: 0.7408860396134341\n",
      "SVM Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.78      0.68      0.72      5246\n",
      "        True       0.71      0.80      0.76      5205\n",
      "\n",
      "    accuracy                           0.74     10451\n",
      "   macro avg       0.74      0.74      0.74     10451\n",
      "weighted avg       0.74      0.74      0.74     10451\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_params = {\n",
    "    'C': [0.1, 1, 10],  # Regularization parameter\n",
    "    'kernel': ['linear', 'rbf', 'poly'],  # Kernel type\n",
    "    'gamma': ['scale', 'auto'],  # Kernel coefficient\n",
    "    'degree': [2, 3, 4],  # Degree of polynomial kernel (only relevant for 'poly' kernel)\n",
    "    'coef0': [0, 0.1, 1],  # Independent term in kernel function (only relevant for 'poly' kernel)\n",
    "}\n",
    "\n",
    "svm_best_params, svm_model = tune_and_train(model_parameters=svm_params,\n",
    "                                                    model_class=SVC, \n",
    "                                                    X=X_train, \n",
    "                                                    y=y_train)\n",
    "\n",
    "# Best parameters for SVM \n",
    "print(\"Best Parameters for SVM Classifier:\", svm_best_params)\n",
    "\n",
    "# Predictions\n",
    "svm_pred = rf_model.predict(X_test)\n",
    "\n",
    "svm_acc, svm_class_report = get_accurancy_score(y_test, rf_pred)\n",
    "\n",
    "# Accuracy and Classification Report\n",
    "print(\"SVM Accuracy:\", accuracy_score(svm_test, svm_pred))\n",
    "print(\"SVM Classification Report:\\n\", classification_report(y_test, svm_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8b21c2-4037-4b9e-843e-9435a57d7fb8",
   "metadata": {},
   "source": [
    "### Dumping SVM Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f8154a96-bd4c-4b13-8aff-8c9ef981e6ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./models/svm_model.pkl']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(svm_best, './models/svm_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403260f3-f42f-4ccd-8cb1-0a64e99d890e",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1c6346c1-7784-4ec7-8a06-aea60afb6012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for Gradient Boosting: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200, 'subsample': 0.8}\n",
      "Gradient Boosting Accuracy: 0.7395464548847\n",
      "Gradient Boosting Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.76      0.70      0.73      5246\n",
      "        True       0.72      0.78      0.75      5205\n",
      "\n",
      "    accuracy                           0.74     10451\n",
      "   macro avg       0.74      0.74      0.74     10451\n",
      "weighted avg       0.74      0.74      0.74     10451\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gb_params = {\n",
    "     'n_estimators': [100, 200, 300],  # Number of trees\n",
    "    'learning_rate': [0.01, 0.1, 0.5],  # Controls how much each tree corrects the previous one\n",
    "    'max_depth': [3, 5, 7],  # Maximum depth of each tree\n",
    "    'subsample': [0.8, 1.0]  # Fraction of samples used for fitting each tree\n",
    "}\n",
    "\n",
    "gb_best_params, gb_model = tune_and_train(model_parameters=gb_params,\n",
    "                                                    model_class=GradientBoostingClassifier, \n",
    "                                                    X=X_train, \n",
    "                                                    y=y_train)\n",
    "\n",
    "# Best parameters for GB\n",
    "print(\"Best Parameters for Gradient Boosting:\", gb_best_params)\n",
    "\n",
    "# Predictions\n",
    "gb_pred = gb_model.predict(X_test)\n",
    "\n",
    "gb_acc, gb_class_report = get_accurancy_score(y_test, rf_pred)\n",
    "\n",
    "# Accuracy and Classification Report\n",
    "print(\"Gradient Boosting Accuracy:\", accuracy_score(svm_test, gb_pred))\n",
    "print(\"Gradient Boosting Report:\\n\", classification_report(y_test, gb_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcf781d-28c7-43b1-8a30-50a823f8ebb9",
   "metadata": {},
   "source": [
    "#### Dumping Gradient Boosting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "037ec60e-4d51-4461-ac95-a9d6097830bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./models/gradient_boosting_model.pkl']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(gb_best, './models/gradient_boosting_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590ad98c-dbdc-462c-a78f-db60a4814761",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ae7914d1-3d35-4e9a-ba5e-5275303d8815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for XGBoost: {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200, 'subsample': 0.8}\n",
      "XGBoost Accuracy: 0.7419385704717252\n",
      "XGBoost Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.77      0.70      0.73      5246\n",
      "        True       0.72      0.79      0.75      5205\n",
      "\n",
      "    accuracy                           0.74     10451\n",
      "   macro avg       0.74      0.74      0.74     10451\n",
      "weighted avg       0.74      0.74      0.74     10451\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the XGBoost model\n",
    "xgb_model = xgb.XGBClassifier(random_state=42, use_label_encoder=False)\n",
    "\n",
    "# Hyperparameter tuning\n",
    "xgb_params = {\n",
    "    'n_estimators': [100, 200, 300],  # Number of trees\n",
    "    'learning_rate': [0.01, 0.1, 0.2],  # Learning rate\n",
    "    'max_depth': [3, 5, 7],  # Maximum depth of each tree\n",
    "    'subsample': [0.8, 1.0],  # Fraction of samples used for fitting each tree\n",
    "    'colsample_bytree': [0.8, 1.0]  # Fraction of features to use for each tree\n",
    "}\n",
    "\n",
    "# GridSearchCV for hyperparameter tuning\n",
    "xgb_grid = GridSearchCV(xgb_model, xgb_params, cv=5, scoring='accuracy')\n",
    "xgb_grid.fit(X_train, y_train)\n",
    "\n",
    "# Best hyperparameters\n",
    "print(\"Best Parameters for XGBoost:\", xgb_grid.best_params_)\n",
    "\n",
    "# Evaluate the best XGBoost model\n",
    "xgb_best = xgb_grid.best_estimator_\n",
    "xgb_pred = xgb_best.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(\"XGBoost Accuracy:\", accuracy_score(y_test, xgb_pred))\n",
    "print(\"XGBoost Classification Report:\\n\", classification_report(y_test, xgb_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a75c17-b4b8-4498-baee-aaa43ad93f91",
   "metadata": {},
   "source": [
    "#### Dumping XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d118c39d-e4d4-40f3-89ce-428e40b9014a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./models/xgboost_model.pkl']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(gb_best, './models/xgboost_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534bf3ce-0217-4076-895b-e8f5263d38fe",
   "metadata": {},
   "source": [
    "## Stacking Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0417be1b-e842-471d-aa76-f1c0f6ed1a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Classifier Accuracy: 0.7445220553057124\n",
      "Stacking Classifier Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.77      0.71      0.73      5246\n",
      "        True       0.73      0.78      0.75      5205\n",
      "\n",
      "    accuracy                           0.74     10451\n",
      "   macro avg       0.75      0.74      0.74     10451\n",
      "weighted avg       0.75      0.74      0.74     10451\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "# Define base models\n",
    "base_models = [\n",
    "    ('log_reg', log_reg_best),\n",
    "    ('rf', rf_best),\n",
    "    ('gb', gb_best),\n",
    "    ('xgb', xgb_best),\n",
    "    ('svm', svm_best)\n",
    "]\n",
    "\n",
    "# Define final estimator (a logistic regression)\n",
    "final_estimator = LogisticRegression()\n",
    "\n",
    "# Create the Stacking Classifier\n",
    "stacking_clf = StackingClassifier(estimators=base_models, final_estimator=final_estimator)\n",
    "\n",
    "# Fit the Stacking Classifier\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the Stacking Classifier\n",
    "stacking_pred = stacking_clf.predict(X_test)\n",
    "print(\"Stacking Classifier Accuracy:\", accuracy_score(y_test, stacking_pred))\n",
    "print(\"Stacking Classifier Classification Report:\\n\", classification_report(y_test, stacking_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cbbc2e-7944-49a3-b3d2-5f82a893fcb0",
   "metadata": {},
   "source": [
    "#### Dumping Stacking Classifer with log reg, rf, fb and xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6081798e-8ceb-4da8-b4e3-b63f2c2f0496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./models/stacking_classifier.pkl']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(stacking_clf, './models/stacking_classifier.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b95246-bf9d-465d-93d2-f90b4beba03a",
   "metadata": {},
   "source": [
    "## Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5c7592cc-3a62-403c-ad01-f4fe7210efab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier Accuracy: 0.7437565783178643\n",
      "Voting Classifier Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.77      0.69      0.73      5246\n",
      "        True       0.72      0.79      0.76      5205\n",
      "\n",
      "    accuracy                           0.74     10451\n",
      "   macro avg       0.75      0.74      0.74     10451\n",
      "weighted avg       0.75      0.74      0.74     10451\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Importing saved model\n",
    "log_reg = joblib.load('./models/logistic_reg_model.pkl')\n",
    "rf = joblib.load('./models/random_forest_model.pkl')\n",
    "\n",
    "# Create Voting Classifier\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('log_reg', log_reg_best),\n",
    "    ('rf', rf_best),\n",
    "    ('gb', gb_best),\n",
    "    ('xgb', xgb_best),\n",
    "    ('svm', svm_best)\n",
    "], voting='hard')\n",
    "\n",
    "# Fit and evaluate the Voting Classifier\n",
    "voting_clf.fit(X_train, y_train)\n",
    "voting_pred = voting_clf.predict(X_test)\n",
    "\n",
    "# Accuracy and Classification Report for Voting Classifier\n",
    "print(\"Voting Classifier Accuracy:\", accuracy_score(y_test, voting_pred))\n",
    "print(\"Voting Classifier Classification Report:\\n\", classification_report(y_test, voting_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d745caa1-1968-4691-ad71-db2f4866679b",
   "metadata": {},
   "source": [
    "#### Dumping Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "80c54e99-a191-4c71-8011-7d7221560e91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./models/voting_classifier.pkl']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(voting_clf, './models/voting_classifier.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4ebb13-9ee5-43ec-94a2-8aa6011c2f1d",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9137f1c2-a969-426f-afcf-28f838d52ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Saved Models\n",
    "\n",
    "log_reg = joblib.load('./models/logistic_reg_model.pkl')\n",
    "rf = joblib.load('./models/random_forest_model.pkl')\n",
    "gb = joblib.load('./models/gradient_boosting_model.pkl') \n",
    "xgb = joblib.load('./models/xgboost_model.pkl')  \n",
    "svm = joblib.load('./models/svm_model.pkl')\n",
    "\n",
    "voting_clf = joblib.load('./models/voting_classifier.pkl')\n",
    "stacking_clf = joblib.load('./models/stacking_classifier.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203b5a92-d8e9-4618-9885-212809242f01",
   "metadata": {},
   "source": [
    "#### Running cross validation voting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d35403bd-8100-4d40-bde2-b5cadd1f8347",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores = cross_val_score(voting_clf, X_train, y_train, cv=5, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0be14dd9-b181-4d90-a99f-fef88303b79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.74533525 0.74307976 0.7279065  0.74528302 0.74138638]\n",
      "Mean Cross-Validation Accuracy: 0.7405981820545888\n"
     ]
    }
   ],
   "source": [
    "print(\"Cross-Validation Accuracy Scores:\", cv_scores)\n",
    "print(\"Mean Cross-Validation Accuracy:\", np.mean(cv_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7a113aab-7efa-4c06-856d-a4e91e0da8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier Accuracy on Test Set: 0.739737824131662\n",
      "Voting Classifier Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.72      0.73      5246\n",
      "           1       0.73      0.76      0.75      5205\n",
      "\n",
      "    accuracy                           0.74     10451\n",
      "   macro avg       0.74      0.74      0.74     10451\n",
      "weighted avg       0.74      0.74      0.74     10451\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit and evaluate the Voting Classifier\n",
    "voting_clf.fit(X_train, y_train)\n",
    "voting_pred = voting_clf.predict(X_test)\n",
    "\n",
    "# Accuracy and Classification Report for Voting Classifier\n",
    "print(\"Voting Classifier Accuracy on Test Set:\", accuracy_score(y_test, voting_pred))\n",
    "print(\"Voting Classifier Classification Report:\\n\", classification_report(y_test, voting_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c035bd-3844-44ff-be33-4d526c550171",
   "metadata": {},
   "source": [
    "#### Running cross validation stacking classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "87605996-f1f5-4abd-8ae8-d53e1fdac436",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_stacking_scores = cross_val_score(stacking_clf, X_train, y_train, cv=5, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "35a35faf-c8e7-4dee-b37b-591379af82d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.74656551 0.74431003 0.73098216 0.74610336 0.74015587]\n",
      "Mean Cross-Validation Accuracy: 0.7416233856563001\n"
     ]
    }
   ],
   "source": [
    "print(\"Cross-Validation Accuracy Scores:\", cv_stacking_scores)\n",
    "print(\"Mean Cross-Validation Accuracy:\", np.mean(cv_stacking_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6c965dca-2a32-4b99-b198-def6ce05f02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Classifier Accuracy on Test Set: 0.739737824131662\n",
      "Stacking Classifier Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.72      0.73      5246\n",
      "           1       0.73      0.76      0.75      5205\n",
      "\n",
      "    accuracy                           0.74     10451\n",
      "   macro avg       0.74      0.74      0.74     10451\n",
      "weighted avg       0.74      0.74      0.74     10451\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit and evaluate the Stacking Classifier\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "stacking_pred = voting_clf.predict(X_test)\n",
    "\n",
    "# Accuracy and Classification Report for Stacking Classifier\n",
    "print(\"Stacking Classifier Accuracy on Test Set:\", accuracy_score(y_test, stacking_pred))\n",
    "print(\"Stacking Classifier Classification Report:\\n\", classification_report(y_test, stacking_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5875d968-bced-46c7-8006-0f9a3a9b54e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
